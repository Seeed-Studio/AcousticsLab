#!/usr/bin/env python3
"""
End-to-End Speech Model Converter for Deployment

This script provides a comprehensive pipeline to convert a speech command model,
originally from TensorFlow.js (like those from Teachable Machine), into a
fully quantized and optimized TensorFlow Lite (`.tflite`) model suitable for
deployment on microcontroller units (MCUs).

The conversion process involves several key stages:
1.  **TF.js to Keras**: Converts the input TF.js model (`model.json`) into an intermediate Keras H5 model (`.h5`).
2.  **Architecture Optimization**: The Keras model architecture was restructured
    by replacing the Dense layer with an equivalent 1x1 convolutional layer. 
    This enables correct inference results on the device.
3.  **Weight Transfer**: Carefully transfers the learned weights from the original
    model to the new, optimized architecture.
4.  **Post-Training Quantization**: Converts the model to TensorFlow Lite format
    while applying full integer quantization (INT8). This step significantly
    reduces the model size and improves inference speed on supported hardware.
    -   It uses a representative dataset, generated by preprocessing `.wav`
        audio files from a specified directory, to ensure accurate quantization
        calibration.
5.  **Metadata Integration**: Reads class labels from a `metadata.json` file to
    correctly configure the model's output layer.

Usage:
    The script can be run from the command line, providing paths to the
    necessary input files and desired output locations.

    Usage:
    $ python convert_speech_model.py --tfjs_model /path/to/model.json \\
                                     --metadata /path/to/metadata.json \\ (Optional)
                                     --wav_dir /path/to/audio_data
    For a full list of options, run:
    $ python convert_speech_model.py --help
"""

import tensorflow as tf
import numpy as np
import logging
import argparse
import sys
import json
import random
import mimetypes
import urllib.request
import tarfile
import os
import librosa
from pathlib import Path
from typing import Optional, List, Dict, Any, Iterator

from tensorflowjs.converters.converter import (
    dispatch_tensorflowjs_to_keras_h5_conversion,
)

logging.basicConfig(
    level=logging.INFO,
    format="[%(asctime)s.%(msecs)03d] [%(levelname)s] %(message)s",
    datefmt="%H:%M:%S",
)

_SCRIPT_DIR = Path(__file__).parent
_PROJECT_ROOT = _SCRIPT_DIR.parent

DEFAULT_TFJS_MODEL_PATH = _PROJECT_ROOT / "tm-my-audio-model" / "model.json"
DEFAULT_METADATA_PATH = _PROJECT_ROOT / "tm-my-audio-model" / "metadata.json"
DEFAULT_KERAS_OUTPUT_PATH = _PROJECT_ROOT / "tm-my-audio-model" / "converted_model.h5"
DEFAULT_TFLITE_OUTPUT_PATH = (
    _PROJECT_ROOT / "tm-my-audio-model" / "quantized_model.tflite"
)
DEFAULT_WAV_INPUT_DIR = _PROJECT_ROOT / "datasound"

REQUIRED_SAMPLES = 100


def download_and_extract_preproc_model(dest_dir: Path) -> Path:
    PREPROC_MODEL_URL = "https://storage.googleapis.com/tfjs-models/tfjs/speech-commands/conversion/sc_preproc_model.tar.gz"
    MODEL_DIR_NAME = "sc_preproc_model"

    dest_dir.mkdir(parents=True, exist_ok=True)
    model_path = dest_dir / MODEL_DIR_NAME

    if model_path.exists():
        logging.info(f"✅ Preprocessing model found at {model_path}")
        return model_path

    logging.info(
        f"Preprocessing model not found. Downloading from {PREPROC_MODEL_URL}..."
    )

    tar_path, _ = urllib.request.urlretrieve(PREPROC_MODEL_URL)
    logging.info(f"Downloaded to temporary file: {tar_path}")

    logging.info(f"Extracting to {dest_dir}...")
    with tarfile.open(tar_path, "r:gz") as tar:
        tar.extractall(path=dest_dir)

    os.remove(tar_path)

    if not model_path.exists():
        raise RuntimeError(f"Failed to extract model to {model_path}")

    logging.info(
        f"✅ Successfully downloaded and extracted preprocessing model to {model_path}"
    )
    return model_path


class ConversionStepFailedError(Exception):
    def __init__(
        self, step_name: str, message: str, original_exception: Exception = None
    ):
        self.step_name = step_name
        self.original_exception = original_exception
        super().__init__(f"Step '{step_name}' failed: {message}")


class ModelConverter:
    def __init__(
        self,
        tfjs_model_path: str = str(DEFAULT_TFJS_MODEL_PATH),
        metadata_path: str = str(DEFAULT_METADATA_PATH),
        keras_output_path: str = str(DEFAULT_KERAS_OUTPUT_PATH),
        tflite_output_path: str = str(DEFAULT_TFLITE_OUTPUT_PATH),
        wav_input_dir: str = str(DEFAULT_WAV_INPUT_DIR),
    ):
        path_configs = {
            "tfjs_model_path": tfjs_model_path,
            "metadata_path": metadata_path,
            "keras_output_path": keras_output_path,
            "tflite_output_path": tflite_output_path,
            "wav_input_dir": wav_input_dir,
        }

        for attr_name, path_value in path_configs.items():
            if not isinstance(path_value, str) or not path_value.strip():
                raise ValueError(f"{attr_name} must be a non-empty string")
            setattr(self, attr_name, Path(path_value.strip()))

        preproc_cache_dir = _PROJECT_ROOT / "tm-my-audio-model"
        self.preproc_model_path = download_and_extract_preproc_model(preproc_cache_dir)

        self._model_info: Dict[str, Any] = {}
        self._labels: List[str] = []
        self._num_classes: Optional[int] = None
        self._original_model: Optional[tf.keras.Model] = None
        self._final_model: Optional[tf.keras.Model] = None
        self._tflite_model: Optional[bytes] = None

        logging.info("🔧 ModelConverter initialized successfully")

    def _check_keras_model_exists(self) -> None:
        if not self.keras_output_path.exists():
            raise ConversionStepFailedError(
                "dependency_check",
                f"Keras model not found at {self.keras_output_path}. "
                "Run convert_tfjs_to_keras() first.",
            )

    def _check_models_created(self) -> None:
        if self._original_model is None or self._final_model is None:
            raise ConversionStepFailedError(
                "dependency_check",
                "Model architectures not created. Run create_models() first.",
            )

    def _infer_num_classes_from_model_json(self) -> int:
        try:
            logging.info("🔄 Inferring number of classes from model.json...")

            with open(self.tfjs_model_path, "r", encoding="utf-8") as f:
                model_config = json.load(f)

            if "modelTopology" not in model_config:
                raise ValueError("No 'modelTopology' found in model.json")

            topology = model_config["modelTopology"]
            config = topology.get("config", {})
            layers = config.get("layers", [])

            if not layers:
                raise ValueError("No layers found in model config")

            output_layers = config.get("output_layers", [])
            if output_layers:
                output_layer_name = output_layers[0][0]
                logging.info(f"Found output layer specification: {output_layer_name}")

                for layer in layers:
                    if layer.get("name") == output_layer_name:
                        if layer.get("class_name") == "Sequential":
                            seq_config = layer.get("config", {})
                            seq_layers = seq_config.get("layers", [])
                            if seq_layers:
                                last_seq_layer = seq_layers[-1]
                                if last_seq_layer.get("class_name") == "Dense":
                                    units = last_seq_layer.get("config", {}).get(
                                        "units"
                                    )
                                    if units is not None:
                                        logging.info(
                                            f"Found output Dense layer in Sequential with {units} units"
                                        )
                                        return units
                        elif layer.get("class_name") == "Dense":
                            units = layer.get("config", {}).get("units")
                            if units is not None:
                                logging.info(
                                    f"Found output Dense layer with {units} units"
                                )
                                return units

            for layer in reversed(layers):
                layer_config = layer.get("config", {})
                class_name = layer.get("class_name", "")

                if (
                    class_name == "Dense"
                    and layer_config.get("activation") == "softmax"
                ):
                    units = layer_config.get("units")
                    if units is not None:
                        logging.info(f"Found softmax Dense layer with {units} units")
                        return units
                elif class_name == "Sequential":
                    seq_layers = layer_config.get("layers", [])
                    for seq_layer in reversed(seq_layers):
                        if (
                            seq_layer.get("class_name") == "Dense"
                            and seq_layer.get("config", {}).get("activation")
                            == "softmax"
                        ):
                            units = seq_layer.get("config", {}).get("units")
                            if units is not None:
                                logging.info(
                                    f"Found softmax Dense layer in Sequential with {units} units"
                                )
                                return units

            for layer in reversed(layers):
                layer_config = layer.get("config", {})
                class_name = layer.get("class_name", "")

                if class_name == "Dense":
                    units = layer_config.get("units")
                    if units is not None:
                        logging.info(
                            f"Found last Dense layer with {units} units (fallback)"
                        )
                        return units

            raise ValueError("No suitable Dense layer found for class count inference")

        except Exception as e:
            raise ConversionStepFailedError(
                "model_json_parsing",
                f"Failed to infer class count from model.json: {e}",
            ) from e

    def _infer_num_classes_from_metadata(self) -> int:
        try:
            logging.info("🔄 Inferring number of classes...")

            if self._labels:
                num_classes = len(self._labels)
                logging.info(f"✅ Using class count from metadata: {num_classes}")
                return num_classes

            try:
                model = tf.keras.models.load_model(str(self.keras_output_path))
                output_shape = model.output_shape
                logging.info(f"Model output shape: {output_shape}")

                if len(output_shape) >= 2 and output_shape[-1] is not None:
                    num_classes = output_shape[-1]
                    logging.info(
                        f"✅ Inferred {num_classes} classes from model output shape"
                    )
                    return num_classes
                else:
                    raise ValueError(
                        f"Cannot determine class count from output shape: {output_shape}"
                    )

            except Exception as model_error:
                logging.warning(
                    f"⚠️  Could not load model for class inference: {model_error}"
                )
                raise ValueError(
                    "Cannot determine number of classes from either metadata or model"
                )

        except Exception as e:
            raise ConversionStepFailedError(
                "class_count_inference", f"Failed to infer number of classes: {e}"
            ) from e

    def _generate_default_labels(self, num_classes: int) -> List[str]:
        return [f"class_{i}" for i in range(num_classes)]

    def _is_audio_file(self, file_path: Path) -> bool:
        try:
            mime_type, _ = mimetypes.guess_type(str(file_path))
            if mime_type and mime_type.startswith("audio/"):
                return True

            audio_extensions = {
                ".wav",
                ".wave",
                ".WAV",
                ".WAVE",
                ".mp3",
                ".MP3",
                ".flac",
                ".FLAC",
                ".ogg",
                ".OGG",
                ".m4a",
                ".M4A",
            }
            if file_path.suffix.lower() in {ext.lower() for ext in audio_extensions}:
                return True

            return False

        except Exception as e:
            logging.debug(f"Error checking file type for {file_path}: {e}")
            return file_path.suffix.lower() in {".wav", ".wave"}

    def _collect_audio_files(self, directory: Path) -> List[Path]:
        audio_files = []

        try:
            for file_path in directory.iterdir():
                if file_path.is_file() and self._is_audio_file(file_path):
                    audio_files.append(file_path)

            logging.debug(f"Found {len(audio_files)} audio files in {directory}")
            return sorted(audio_files)

        except Exception as e:
            raise ConversionStepFailedError(
                "audio_file_collection",
                f"Failed to collect audio files from {directory}: {e}",
            ) from e

    def _validate_and_sample_audio_files(self) -> List[Path]:
        try:
            wav_dir = Path(self.wav_input_dir)

            audio_files = self._collect_audio_files(wav_dir)

            logging.info(f"Found {len(audio_files)} audio files in {wav_dir}")

            if len(audio_files) < REQUIRED_SAMPLES:
                raise ConversionStepFailedError(
                    "dataset_validation",
                    f"Insufficient audio files: found {len(audio_files)}, "
                    f"required at least {REQUIRED_SAMPLES}",
                )

            if len(audio_files) > REQUIRED_SAMPLES:
                selected_files = random.sample(audio_files, REQUIRED_SAMPLES)
                logging.info(
                    f"Randomly sampled {REQUIRED_SAMPLES} files from {len(audio_files)} available"
                )
            else:
                selected_files = audio_files
                logging.info(f"Using all {len(selected_files)} available files")

            return selected_files

        except ConversionStepFailedError:
            raise
        except Exception as e:
            raise ConversionStepFailedError(
                "dataset_validation", f"Failed to validate and sample audio files: {e}"
            ) from e

    def _generate_features_from_wavs(self) -> Iterator[np.ndarray]:
        logging.info(
            "--- Starting feature generation from audio files for quantization ---"
        )

        audio_files = self._validate_and_sample_audio_files()

        logging.info(
            f"Processing {len(audio_files)} audio files to generate representative data..."
        )

        try:
            preproc_model = tf.saved_model.load(str(self.preproc_model_path))
            inference_func = preproc_model.signatures["serving_default"]
            input_details = inference_func.inputs[0]
            target_len = input_details.shape[1]
            target_sr = 44100

            for audio_path in audio_files:
                try:
                    data, _ = librosa.load(str(audio_path), sr=target_sr, mono=True)
                    if len(data) > target_len:
                        data = data[
                            (len(data) - target_len) // 2 : (len(data) + target_len)
                            // 2
                        ]
                    else:
                        data = np.pad(data, (0, target_len - len(data)), "constant")

                    model_input_audio = tf.constant(
                        data.reshape(1, target_len), dtype=input_details.dtype
                    )
                    result_dict = inference_func(model_input_audio)
                    feature_map = list(result_dict.values())[0].numpy()
                    yield [feature_map.astype(np.float32)]

                except Exception as e:
                    logging.warning(
                        f"Could not process audio file '{audio_path.name}': {e}. Skipping."
                    )
                    continue

        except Exception as e:
            raise ConversionStepFailedError(
                "feature_generation",
                f"Failed to initialize preprocessing model or generate features: {e}",
            ) from e

    def _representative_data_gen(self):
        try:
            yield from self._generate_features_from_wavs()
        except FileNotFoundError:
            logging.error(
                "Failed to generate data from WAVs. Falling back to 200 random samples for calibration."
            )

    def convert_tfjs_to_keras(self) -> None:
        logging.info(
            f"--- Step 1: Converting {self.tfjs_model_path} to {self.keras_output_path} ---"
        )

        try:
            logging.info("🔄 Converting TF.js model using tensorflowjs converter...")

            self.keras_output_path.parent.mkdir(parents=True, exist_ok=True)

            dispatch_tensorflowjs_to_keras_h5_conversion(
                str(self.tfjs_model_path),
                str(self.keras_output_path),
            )

            logging.info("TensorFlow.js to Keras conversion completed successfully")

            if (
                not self.keras_output_path.exists()
                or self.keras_output_path.stat().st_size == 0
            ):
                raise RuntimeError("Keras model file was not created or is empty")

            file_size = self.keras_output_path.stat().st_size
            logging.info(
                f"✅ TF.js to Keras conversion successful! Output size: {file_size:,} bytes"
            )

        except Exception as e:
            raise ConversionStepFailedError(
                "tfjs_to_keras_conversion",
                f"Failed to convert TF.js model to Keras: {e}",
            ) from e

    def load_metadata(self) -> None:
        logging.info(
            f"--- Step 2: Loading metadata from {self.metadata_path} (optional) ---"
        )

        if not self.metadata_path.exists():
            logging.info(
                f"ℹ️  Metadata file not found: {self.metadata_path}. Will use default labels."
            )
            self._labels = []
            return

        try:
            logging.info(f"🔄 Attempting to read metadata from {self.metadata_path}...")

            with open(self.metadata_path, "r", encoding="utf-8") as f:
                metadata = json.load(f)

            if not isinstance(metadata, dict):
                raise ValueError(
                    f"Metadata must be a JSON object, got {type(metadata)}"
                )

            if "wordLabels" not in metadata:
                raise ValueError("No 'wordLabels' key found in metadata")

            word_labels = metadata["wordLabels"]
            if not isinstance(word_labels, list) or not word_labels:
                raise ValueError("'wordLabels' must be a non-empty list")

            for i, label in enumerate(word_labels):
                if not isinstance(label, str) or not label.strip():
                    raise ValueError(f"Invalid label at index {i}: {label}")

            self._labels = [label.strip() for label in word_labels]
            logging.info(
                f"✅ Loaded {len(self._labels)} labels from metadata: {self._labels}"
            )

        except Exception as e:
            logging.info(
                f"ℹ️  Could not load metadata from {self.metadata_path}: {e}. "
                f"Will use default labels based on model.json."
            )
            self._labels = []

    def create_models(self) -> None:
        self._check_keras_model_exists()

        logging.info("--- Step 3: Creating model architectures ---")

        try:
            self._num_classes = self._infer_num_classes_from_model_json()
            logging.info(f"✅ Using class count from model.json: {self._num_classes}")
        except ConversionStepFailedError as e:
            logging.warning(f"⚠️  Failed to infer class count from model.json: {e}")
            # Fallback to metadata if available
            if self._labels:
                self._num_classes = len(self._labels)
                logging.info(f"✅ Using class count from metadata: {self._num_classes}")
            else:
                raise ConversionStepFailedError(
                    "class_count_inference",
                    "Cannot determine class count from either model.json or metadata",
                )

        default_labels = self._generate_default_labels(self._num_classes)

        if self._labels and len(self._labels) == self._num_classes:
            logging.info(f"✅ Using metadata labels: {self._labels}")
        else:
            if self._labels and len(self._labels) != self._num_classes:
                logging.warning(
                    f"⚠️  Metadata label count ({len(self._labels)}) doesn't match "
                    f"inferred class count ({self._num_classes}). Using default labels."
                )
            self._labels = default_labels
            logging.info(f"✅ Using default labels: {self._labels}")

        logging.info(f"🔄 Creating models for {self._num_classes} classes...")
        logging.info(f"Using labels: {self._labels}")

        try:
            logging.info("🔄 Building original model architecture...")
            inputs = tf.keras.layers.Input(shape=(43, 232, 1), name="conv2d_1_input")
            x = tf.keras.layers.Conv2D(
                8, kernel_size=(2, 8), activation="relu", name="conv2d_1"
            )(inputs)
            x = tf.keras.layers.MaxPooling2D(
                pool_size=(2, 2), strides=(2, 2), name="max_pooling2d_1"
            )(x)
            x = tf.keras.layers.Conv2D(
                32, kernel_size=(2, 4), activation="relu", name="conv2d_2"
            )(x)
            x = tf.keras.layers.MaxPooling2D(
                pool_size=(2, 2), strides=(2, 2), name="max_pooling2d_2"
            )(x)
            x = tf.keras.layers.Conv2D(
                32, kernel_size=(2, 4), activation="relu", name="conv2d_3"
            )(x)
            x = tf.keras.layers.MaxPooling2D(
                pool_size=(2, 2), strides=(2, 2), name="max_pooling2d_3"
            )(x)
            x = tf.keras.layers.Conv2D(
                32, kernel_size=(2, 4), activation="relu", name="conv2d_4"
            )(x)
            x_before_flatten = tf.keras.layers.MaxPooling2D(
                pool_size=(2, 2), strides=(1, 2), name="max_pooling2d_4"
            )(x)
            x_flat = tf.keras.layers.Flatten(name="flatten_1")(x_before_flatten)
            x_dropout = tf.keras.layers.Dropout(0.25, name="dropout_1")(x_flat)
            x_dense = tf.keras.layers.Dense(2000, activation="relu", name="dense_1")(
                x_dropout
            )
            outputs = tf.keras.layers.Dense(
                self._num_classes, activation="softmax", name="NewHeadDense"
            )(x_dense)
            self._original_model = tf.keras.Model(
                inputs=inputs, outputs=outputs, name="original_model"
            )

            if self._original_model is None:
                raise RuntimeError("Failed to create original model")

            logging.info(
                f"✅ Original model created with {self._original_model.count_params():,} parameters"
            )

            inputs = tf.keras.layers.Input(shape=(43, 232, 1), name="conv2d_1_input")
            x = tf.keras.layers.Conv2D(
                8, kernel_size=(2, 8), activation="relu", name="conv2d_1"
            )(inputs)
            x = tf.keras.layers.MaxPooling2D(
                pool_size=(2, 2), strides=(2, 2), name="max_pooling2d_1"
            )(x)
            x = tf.keras.layers.Conv2D(
                32, kernel_size=(2, 4), activation="relu", name="conv2d_2"
            )(x)
            x = tf.keras.layers.MaxPooling2D(
                pool_size=(2, 2), strides=(2, 2), name="max_pooling2d_2"
            )(x)
            x = tf.keras.layers.Conv2D(
                32, kernel_size=(2, 4), activation="relu", name="conv2d_3"
            )(x)
            x = tf.keras.layers.MaxPooling2D(
                pool_size=(2, 2), strides=(2, 2), name="max_pooling2d_3"
            )(x)
            x = tf.keras.layers.Conv2D(
                32, kernel_size=(2, 4), activation="relu", name="conv2d_4"
            )(x)
            x_before_flatten = tf.keras.layers.MaxPooling2D(
                pool_size=(2, 2), strides=(1, 2), name="max_pooling2d_4"
            )(x)

            logging.info("🔄 Building optimized model architecture...")
            H, W = (x_before_flatten.shape[1], x_before_flatten.shape[2])
            if H is None or W is None:
                raise RuntimeError(
                    f"Cannot determine feature map dimensions. Got H={H}, W={W}\n"
                    f"This may indicate an issue with the model architecture."
                )

            x_conv1 = tf.keras.layers.Conv2D(
                2000,
                kernel_size=(H, W),
                activation="relu",
                name="dense_1_conv_replacement",
            )(x_before_flatten)
            x_flat1 = tf.keras.layers.Flatten(name="flatten_1")(x_conv1)
            x_dropout = tf.keras.layers.Dropout(0.25, name="dropout_1")(x_flat1)
            x_reshaped = tf.keras.layers.Reshape((1, 1, 2000))(x_dropout)
            x_conv2 = tf.keras.layers.Conv2D(
                self._num_classes,
                kernel_size=(1, 1),
                activation="softmax",
                name="NewHeadDense_conv_replacement",
            )(x_reshaped)
            outputs = tf.keras.layers.Flatten(name="output_flatten")(x_conv2)

            self._final_model = tf.keras.Model(
                inputs=inputs, outputs=outputs, name="optimized_model"
            )

            if self._original_model is None:
                raise RuntimeError("Failed to create original model architecture")
            if self._final_model is None:
                raise RuntimeError("Failed to create optimized model architecture")

            expected_output_shape = (None, self._num_classes)
            if self._original_model.output_shape != expected_output_shape:
                raise RuntimeError(
                    f"Original model output shape mismatch. Expected {expected_output_shape}, "
                    f"got {self._original_model.output_shape}"
                )
            if self._final_model.output_shape != expected_output_shape:
                raise RuntimeError(
                    f"Optimized model output shape mismatch. Expected {expected_output_shape}, "
                    f"got {self._final_model.output_shape}"
                )

            logging.info(
                f"✅ Original model created with {self._original_model.count_params():,} parameters"
            )
            logging.info(
                f"✅ Optimized model created with {self._final_model.count_params():,} parameters"
            )
            logging.info("✅ Model architectures created successfully!")

        except Exception as e:
            raise ConversionStepFailedError(
                "model_creation", f"Failed to create model architectures: {e}"
            ) from e

    def transfer_weights(self) -> None:
        self._check_models_created()

        logging.info("--- Step 4: Loading and transferring weights ---")

        try:
            logging.info(f"🔄 Loading weights from {self.keras_output_path}...")
            self._original_model.load_weights(str(self.keras_output_path))

            for layer_new in self._final_model.layers:
                if not layer_new.get_weights():
                    continue
                try:
                    source_layer = self._original_model.get_layer(name=layer_new.name)
                    layer_new.set_weights(source_layer.get_weights())
                except ValueError:
                    pass

            logging.info("✅ Weights loaded successfully")
            logging.info("🔄 Transferring weights to optimized model...")

            dense1_orig = self._original_model.get_layer("dense_1")
            conv1_new = self._final_model.get_layer("dense_1_conv_replacement")
            weights, biases = dense1_orig.get_weights()
            H, W, C_in, C_out = conv1_new.get_weights()[0].shape
            weights_reshaped = weights.reshape((H, W, C_in, C_out))
            conv1_new.set_weights([weights_reshaped, biases])
            logging.info(
                "  - Manually transferred: dense_1 -> dense_1_conv_replacement"
            )

            dense2_orig = self._original_model.get_layer("NewHeadDense")
            conv2_new = self._final_model.get_layer("NewHeadDense_conv_replacement")
            weights, biases = dense2_orig.get_weights()
            H, W, C_in, C_out = conv2_new.get_weights()[0].shape
            weights_reshaped = weights.reshape((H, W, C_in, C_out))
            conv2_new.set_weights([weights_reshaped, biases])
            logging.info(
                "  - Manually transferred: NewHeadDense -> NewHeadDense_conv_replacement"
            )

            logging.info("✅ Weight transfer completed!")

        except Exception as e:
            raise ConversionStepFailedError(
                "weight_transfer", f"Failed to transfer weights: {e}"
            ) from e

    def quantize_and_convert(self) -> None:
        self._check_models_created()

        logging.info("--- Step 5: Quantizing and converting to TFLite ---")

        try:

            @tf.function
            def model_func(input_tensor):
                return self._final_model(input_tensor)

            fixed_input_spec = tf.TensorSpec(shape=[1, 43, 232, 1], dtype=tf.float32)
            concrete_func = model_func.get_concrete_function(fixed_input_spec)

            converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
            converter.optimizations = [tf.lite.Optimize.DEFAULT]
            converter.representative_dataset = self._representative_data_gen
            converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
            converter.inference_input_type = tf.int8
            converter.inference_output_type = tf.int8

            self._tflite_model = converter.convert()

            self.tflite_output_path.parent.mkdir(parents=True, exist_ok=True)

            with open(self.tflite_output_path, "wb") as f:
                f.write(self._tflite_model)

            logging.info(f"✅ Quantized TFLite model saved: {self.tflite_output_path}")

            interpreter = tf.lite.Interpreter(model_content=self._tflite_model)
            interpreter.allocate_tensors()

            input_details = interpreter.get_input_details()[0]
            output_details = interpreter.get_output_details()[0]

            self._model_info = {
                "input_shape": input_details["shape"].tolist(),
                "input_dtype": str(input_details["dtype"]),
                "input_scale": float(input_details["quantization"][0]),
                "input_zero_point": int(input_details["quantization"][1]),
                "output_shape": output_details["shape"].tolist(),
                "output_dtype": str(output_details["dtype"]),
                "output_scale": float(output_details["quantization"][0]),
                "output_zero_point": int(output_details["quantization"][1]),
                "model_size": len(self._tflite_model),
                "num_classes": self._num_classes,
                "class_labels": self._labels,
            }

            logging.info(
                f"✅ Model info extracted: {self._model_info['input_shape']} -> {self._model_info['output_shape']}"
            )

        except Exception as e:
            raise ConversionStepFailedError(
                "quantization_and_conversion",
                f"Failed to quantize and convert model: {e}",
            ) from e

    def get_model_info(self) -> Dict[str, Any]:
        if not self._model_info:
            raise RuntimeError(
                "Model conversion must be completed before accessing model info"
            )
        return self._model_info.copy()

    def get_labels(self) -> List[str]:
        if not self._labels:
            raise RuntimeError(
                "Labels not available. Run load_metadata() or create_models() first."
            )
        return self._labels.copy()

    def get_tflite_model(self) -> bytes:
        if self._tflite_model is None:
            raise RuntimeError(
                "Model conversion must be completed before accessing TFLite model"
            )
        return self._tflite_model

    def run(self) -> None:
        logging.info("🚀 Starting Optimized AcousticsLab Model Conversion Pipeline")
        logging.info("=" * 65)

        try:
            self.convert_tfjs_to_keras()

            self.load_metadata()

            self.create_models()

            self.transfer_weights()

            self.quantize_and_convert()

            logging.info("\n" + "=" * 65)
            logging.info("🎉 Conversion completed successfully!")
            logging.info("📁 Generated files:")
            logging.info(f"   - TFLite model: {self.tflite_output_path}")
            logging.info("\n📋 Model summary:")
            logging.info(f"   - Input shape: {self._model_info['input_shape']}")
            logging.info(f"   - Output classes: {self._model_info['num_classes']}")
            logging.info(f"   - Model size: {self._model_info['model_size']:,} bytes")
            logging.info(f"   - Labels: {', '.join(self._labels)}")
            logging.info("\n✨ TFLite model ready for deployment!")

        except ConversionStepFailedError:
            raise
        except Exception as e:
            raise ConversionStepFailedError(
                "pipeline_execution", f"Unexpected error in conversion pipeline: {e}"
            ) from e


def main():
    parser = argparse.ArgumentParser(
        description="Optimized Model Converter for AcousticsLab. Converts TF.js models to TFLite."
    )

    parser.add_argument(
        "--tfjs_model",
        type=str,
        default=str(DEFAULT_TFJS_MODEL_PATH),
        help="Path to the input TF.js model.json file",
    )

    parser.add_argument(
        "--metadata",
        type=str,
        default=str(DEFAULT_METADATA_PATH),
        help=f"Path to the input metadata.json file (optional). Default: {DEFAULT_METADATA_PATH}",
    )

    parser.add_argument(
        "--keras_output",
        type=str,
        default=str(DEFAULT_KERAS_OUTPUT_PATH),
        help=f"Path to save the intermediate Keras .h5 model. Default: {DEFAULT_KERAS_OUTPUT_PATH}",
    )
    parser.add_argument(
        "--tflite_output",
        type=str,
        default=str(DEFAULT_TFLITE_OUTPUT_PATH),
        help=f"Path to save the final quantized .tflite model. Default: {DEFAULT_TFLITE_OUTPUT_PATH}",
    )
    parser.add_argument(
        "--wav_dir",
        type=str,
        default=str(DEFAULT_WAV_INPUT_DIR),
        help=f"Directory containing input .wav files for quantization calibration. Default: {DEFAULT_WAV_INPUT_DIR}",
    )

    args = parser.parse_args()

    logging.info("📁 Input configuration:")
    logging.info(f"   - TF.js model: {args.tfjs_model}")
    logging.info(f"   - Metadata: {args.metadata} (optional)")
    logging.info(f"   - Audio directory: {args.wav_dir}")
    logging.info("📁 Output configuration:")
    logging.info(f"   - Keras model: {args.keras_output}")
    logging.info(f"   - TFLite model: {args.tflite_output}")

    try:
        converter = ModelConverter(
            tfjs_model_path=args.tfjs_model,
            metadata_path=args.metadata,
            keras_output_path=args.keras_output,
            tflite_output_path=args.tflite_output,
            wav_input_dir=args.wav_dir,
        )
        converter.run()

    except ConversionStepFailedError as e:
        logging.error(f"❌ Conversion failed at step '{e.step_name}': {e}")
        if e.original_exception:
            logging.debug(f"Original exception: {e.original_exception}")
        sys.exit(1)

    except KeyboardInterrupt:
        logging.info("\n⚠️  Conversion interrupted by user")
        sys.exit(130)

    except Exception as e:
        logging.critical(f"❌ An unexpected error occurred during conversion: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
